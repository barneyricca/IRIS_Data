---
title: "Data Merge"
output: word_document
date: "2025-05-27"
---

To do:

- Last Day COPE questions appear to be [1,4] not [0,3]. 8 December 2025: Asked Alex

```{r setup}
#| include: FALSE
#| 
knitr::opts_chunk$set(echo = TRUE)

for(packageName in c("here",
                     "magrittr",
                     "purrr",
                     "tidyverse")) {
  if(!is.element(packageName,               # If package is NOT installed...
                 installed.packages()[,1])) {
    install.packages(packageName)           #  ...then install it.
  }
  library(packageName,                      # Add package to environment
          character.only=TRUE,
          quietly=TRUE,
          verbose=FALSE)
}

i_am("Scripts/Data Merge.Rmd") # To help find all the files.

options(show.signif.stars = FALSE)          # Don't stargaze
options(digits = 3)                         # Round to 3 digits by default

```

```{r functions}
select_ampm <- function(df) {
  require(tidyverse)

  df %>% select(starts_with("ampm")) ->
    df1

  apply(df1,
        1,
        function(x)
          min(which(is.na(x) == FALSE))) ->
    dd

  rep(NA, nrow(df1)) -> time_vec

  for(index in 1:nrow(df1)) {
    unlist(df1[index, dd[index]]) -> time_vec[index]
  }

  return(time_vec)
}

select_date <- function(df) {
  require(tidyverse)
  
  df %>% 
    select(starts_with("date")) ->
    df1
  
  apply(df1,
        1,
        function(x) 
          min(which(is.na(x) == FALSE))) ->
    dd
  
  rep(NA, nrow(df1)) -> date_vec
  
  for(index in 1:nrow(df1)) {
    unlist(df1[index, dd[index]]) -> date_vec[index]
  }

  as.Date(date_vec) ->
    date_vec

  return(date_vec)
}

select_time <- function(df) {
  require(tidyverse)
  require(lubridate)

  df %>% 
    select(starts_with("scheduled_start_local")) ->
    df1
  
  apply(df1,
        1,
        function(x) 
          min(which(is.na(x) == FALSE))) ->
    dd
  
  rep(NA, nrow(df1)) -> time_vec
  
  for(index in 1:nrow(df1)) {
    unlist(df1[index, dd[index]]) -> time_vec[index]
  }

  as_datetime(time_vec) ->
    time_vec
  
  3600 * hour(time_vec) +
    60 * minute(time_vec) +
    second(time_vec) ->
    time_vec

  return(time_vec)
}

```

# Read EMA Data

```{r read_codes}
read.csv(here("IRIS codes.csv")) ->
  codes_df
```

Important notes (Updated 1 December 2025):

1. Each file has a varying number (and names) of columns, so this is hard coded. 
2. Note that the rsp_id limits must be checked as well. Currently the range of valid rsp_id is {[64400, 65000], [67000,]}  with everything not in that range assumed to be testing entries; the testing entries are removed.
3. A 13th file was added, 10952000.csv. This file is used for the last EMA session, as it has additional data. That file must be (originally) treated separately.
4. PTDI_SF was added to the Qualtic survey.

```{r read_EMA}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE
#| 

list() -> ema_ls

dir(path = here("ema"),                     # Work in this directory
    pattern = ".csv") -> file_names         # Get the names of all .CSV files

file_names[1] ->                            # Update for new ending EMA
  last_ema_name
file_names[-1] ->
  file_names

for(index in 1:(length(file_names)/2)) {
  2 * index  -> index2                      # Morning and evening EMA have
  index2 - 1 -> index1                      #  different number of columns
  
  read_csv(file = here(paste0("ema/",
                              file_names[index1])),
           col_select = 1:47) ->
    ema_ls[[index1]]
  NULL -> attr(ema_ls[[index1]], "spec")
  paste0(ema_ls[[index1]]$rsp_id, 
         ema_ls[[index1]]$scheduled_start_local) ->
    ema_ls[[index1]]$key
  as_date(ema_ls[[index1]]$scheduled_start_local) ->
    ema_ls[[index1]]$date
  ifelse(
    str_split_i(ema_ls[[index1]]$scheduled_start_local,
                pattern = " |:",
                i = 2) < 12, "am", "pm") ->
    ema_ls[[index1]]$ampm
  
  
  read_csv(file = here(paste0("ema/",
                              file_names[index2])),
           col_select = 1:51) ->
    ema_ls[[index2]]
  NULL -> attr(ema_ls[[index2]], "spec")
  paste0(ema_ls[[index2]]$rsp_id, 
         ema_ls[[index2]]$scheduled_start_local) ->
    ema_ls[[index2]]$key
  as_date(ema_ls[[index2]]$scheduled_start_local) ->
    ema_ls[[index2]]$date
  ifelse(
    str_split_i(ema_ls[[index2]]$scheduled_start_local,
                pattern = " |:",
                i = 2) < 12, "am", "pm") ->
    ema_ls[[index2]]$ampm
}
```

```{r lastDay}

read_csv(file = here(paste0("ema/",
                            last_ema_name)),
         col_select = 1:49) ->
  ema_ls[[13]]
read_csv(file = here(paste0("ema/",
                            last_ema_name)),
         col_select = 77:78) ->
  audio_cols
  
cbind(ema_ls[[13]],
      audio_cols) ->
  ema_ls[[13]]
  
NULL -> attr(ema_ls[[13]], "spec")
paste0(ema_ls[[13]]$rsp_id, 
       ema_ls[[13]]$scheduled_start_local) ->
  ema_ls[[13]]$key
as_date(ema_ls[[13]]$scheduled_start_local) ->
  ema_ls[[13]]$date
ifelse(
  str_split_i(ema_ls[[13]]$scheduled_start_local,
              pattern = " |:",
              i = 2) < 12, "am", "pm") ->
  ema_ls[[13]]$ampm

# Not run:
# which(colnames(ema_ls[[12]]) != colnames(ema_ls[[13]]))
# [1] 33 45 46
# The last day has a _LD inserted into the column name for these three
#  Do we care? I don't know, so...
# Add a "Last Day" column to every frame, and change the last day column
#  names.

# # Add a last day marker to each data frame:
for(index in 1:length(file_names)) {        #
  FALSE ->
    ema_ls[[index]]$last_day
}
TRUE ->
  ema_ls[[13]]$last_day

# Last day PM has questions in a different order than the 6th day PM
ema_ls[[13]][c("mbl_cod", "rsp_id", "instance_id",
               "scheduled_start_local", "timezone_offset", "COPE_5",      
               "COPE_6", "COPE_4", "COPE_2", 
               "COPE_1", "COPE_3", "PANASSF_7", 
               "PANASSF_9", "PANASSF_4", "PANASSF_12", 
               "PANASSF_15", "PANASSF_14", "PANASSF_13", 
               "PANASSF_16", "PANASSF_18", "PANASSF_19", 
               "MSPSS_7", "MSPSS_10", "MSPSS_8", 
               "MSPSS_6", "MSPSS_11", "MSPSS_2", 
               "PTGISF_6", "PTGISF_10", "PTGISF_7", 
               "PTGISF_2", "PTGISF_8", "PRCS_S6_PM_LD", 
               "PROMIS_3A_1", "PROMIS_8A_1", "PSQ_2", 
               "PSQ_4", "PSQ_8", "PSQ_3", 
               "ROE_4", "ROE_2", "CSET_1", 
               "CSET_2", "CSET_8", "REC_1_S6_PM_LD_CAN_SKP_AUD",
               "REC_2_S6_PM_LD_CAN_SKP_AUD", "PTDISF_5", "PTDISF_7", 
               "PTDISF_1", "PTDISF_6", "PTDISF_3", 
               "key", "date", "ampm", 
               "last_day")] ->
  ema_ls[[13]]

colnames(ema_ls[[12]]) ->                   # Rename columns in last_day
  colnames(ema_ls[[13]])

# Rename all the recording files


```

```{r merge_EMA}
lapply(                                     # Remove the testing rsp_id
  ema_ls,    
  function(x) x %>%                         # 
    filter(rsp_id %in% codes_df$rsp_id)) ->
  ema_ls

# unique(                                       # This should be redundant, but
#   c(ema_ls[[1]]$mbl_cod, ema_ls[[2]]$mbl_cod, # check it anyway! ema_ls[[1]]
#     ema_ls[[3]]$mbl_cod, ema_ls[[4]]$mbl_cod, # should contain them all.
#     ema_ls[[5]]$mbl_cod, ema_ls[[6]]$mbl_cod,
#     ema_ls[[7]]$mbl_cod, ema_ls[[8]]$mbl_cod,
#     ema_ls[[9]]$mbl_cod, ema_ls[[10]]$mbl_cod, 
#     ema_ls[[11]]$mbl_cod, ema_ls[[12]]$mbl_cod,
#     ema_ls[[13]]$mbl_cod)) ->
#   valid_mobile_codes

save(ema_ls,
     file = here("ema/EMA List.RData"))
```

```{r ema_names}

for(index in 1:length(ema_ls)) {
  "PRCS" -> colnames(
    ema_ls[[index]])[which(startsWith(colnames(ema_ls[[index]]),"PRCS"))]
  "REC1" -> colnames(
    ema_ls[[index]])[which(startsWith(colnames(ema_ls[[index]]),"REC_1"))]
  "REC2" -> colnames(
    ema_ls[[index]])[which(startsWith(colnames(ema_ls[[index]]),"REC_2"))]
}

sort(
  unique(
    c(colnames(ema_ls[[1]]),
      colnames(ema_ls[[2]]),
      colnames(ema_ls[[3]]),
      colnames(ema_ls[[4]]),
      colnames(ema_ls[[5]]),
      colnames(ema_ls[[6]]),
      colnames(ema_ls[[7]]),
      colnames(ema_ls[[8]]),
      colnames(ema_ls[[9]]),
      colnames(ema_ls[[10]]),
      colnames(ema_ls[[11]]),
      colnames(ema_ls[[12]]),
      colnames(ema_ls[[13]])))) ->          # Redundant; same as ema_ls[[12]]
  ema_names

```

### Data Merging

```{r merge_EMA}
as.data.frame(                              # Create a data frame of the
  matrix(NA,                                #  correct size
         nrow = sum(sapply(ema_ls, nrow)),  # Sum of all of the rows of data
         ncol = length(ema_names),          # Sorted, unique names above
         dimnames = list(NULL,              # No row names
                         ema_names))) ->    # column names
  ema_df

1 ->                                        # Running count
  row_number

for(index1 in 1:length(ema_ls)) {           # For each survey
  for(index2 in 1:nrow(ema_ls[[index1]])) { # For each row in the survey
    ema_ls[[index1]][index2, ] ->           # Store in the correct [row,column]
      ema_df[row_number, colnames(ema_ls[[index1]])]
    row_number + 1 ->                       # Increment the row
      row_number
  }
}


```

Fix particular missingness:

```{r}
NA ->                                       # Skipped 1 or more EMA: COPE, CSET,
  ema_df[ema_df == -9]                      #  MSPSS, PSQ, PANAS, PTGI, ROE
NA ->                                       # Skipped LSET question(s)
  ema_df[ema_df == -1]
  
```

Check the data integrity: Are there any data outside the scale range?

```{r check_ema_values}

# These should all return integer(0) if the data meet the integrity check.

apply(
  ema_df %>%
    select(starts_with("COPE")),
  2,
  function(x) which(x > 3 | x < 0))         # COPE scale range: [0,3]

apply(
  ema_df %>%
    select(starts_with("CSET")),
  2,
  function(x) which(x > 7 | x < 1))         # CSET scale range: [1,7]

apply(
  ema_df %>%
    select(starts_with("LSEQ")),
  2,
  function(x) which(x > 100 | x < 0))

apply(
  ema_df %>%
    select(starts_with("MSPSS")),
  2,
  function(x) which(x > 7 | x < 1))

apply(
  ema_df %>%
    select(starts_with("PANASSF")),
  2,
  function(x) which(x > 5 | x < 1))

apply(
  ema_df %>%
    select(starts_with("PROMIS")),
  2,
  function(x) which(x > 5 | x < 1))

apply(
  ema_df %>%
    select(starts_with("PSQ")),
  2,
  function(x) which(x > 4 | x < 1))

apply(
  ema_df %>%
    select(starts_with("PTDI")),
  2,
  function(x) which(x > 5 | x < 0))

apply(
  ema_df %>%
    select(starts_with("PTGI")),
  2,
  function(x) which(x > 5 | x < 0))

apply(
  ema_df %>%
    select(starts_with("ROE")),
  2,
  function(x) which(x > 5 | x < 1))

```


Step 3: Put the subscale designation into the column names. (E.g. A column name of "PSQ_1" becomes "PSQ_Demands_1" and so on.)

Be careful! Find and replace is tricky because "PANASSF_1" also finds "PANASSF_10", "PANASSF_11", etc.

Some scales do not have subscales.
```{r augmentColumnNames}

# colnames(ema_df)
#  [1] "ampm"                  "COPE_1"                "COPE_2"               
#  [4] "COPE_3"                "COPE_4"                "COPE_5"               
#  [7] "COPE_6"                "CSET_1"                "CSET_2"               
# [10] "CSET_3"                "CSET_4"                "CSET_5"               
# [13] "CSET_6"                "CSET_7"                "CSET_8"               
# [16] "CSET_9"                "date"                  "instance_id"          
# [19] "key"                   "last_day"              "LSEQ_Restlessness"    
# [22] "LSEQ_Wakefulness"      "mbl_cod"               "MSPSS_1"              
# [25] "MSPSS_10"              "MSPSS_11"              "MSPSS_12"             
# [28] "MSPSS_2"               "MSPSS_3"               "MSPSS_4"              
# [31] "MSPSS_5"               "MSPSS_6"               "MSPSS_7"              
# [34] "MSPSS_8"               "MSPSS_9"               "PANASSF_1"            
# [37] "PANASSF_10"            "PANASSF_11"            "PANASSF_12"           
# [40] "PANASSF_13"            "PANASSF_14"            "PANASSF_15"           
# [43] "PANASSF_16"            "PANASSF_17"            "PANASSF_18"           
# [46] "PANASSF_19"            "PANASSF_2"             "PANASSF_20"           
# [49] "PANASSF_3"             "PANASSF_4"             "PANASSF_5"            
# [52] "PANASSF_6"             "PANASSF_7"             "PANASSF_8"            
# [55] "PANASSF_9"             "PRCS"                  "PROMIS_3A_1"          
# [58] "PROMIS_8A_1"           "PSQ_1"                 "PSQ_2"                
# [61] "PSQ_3"                 "PSQ_4"                 "PSQ_5"                
# [64] "PSQ_6"                 "PSQ_7"                 "PSQ_8"                
# [67] "PTDISF_1"              "PTDISF_10"             "PTDISF_2"             
# [70] "PTDISF_3"              "PTDISF_4"              "PTDISF_5"             
# [73] "PTDISF_6"              "PTDISF_7"              "PTDISF_8"             
# [76] "PTDISF_9"              "PTGISF_1"              "PTGISF_10"            
# [79] "PTGISF_2"              "PTGISF_3"              "PTGISF_4"             
# [82] "PTGISF_5"              "PTGISF_6"              "PTGISF_7"             
# [85] "PTGISF_8"              "PTGISF_9"              "REC1"                 
# [88] "REC2"                  "ROE_1"                 "ROE_2"                
# [91] "ROE_3"                 "ROE_4"                 "ROE_5"                
# [94] "ROE_6"                 "rsp_id"                "scheduled_start_local"
# [97] "timezone_offset"              

c("ampm",
  "COPE_Approach_1", "COPE_Approach_2", 
  "COPE_Approach_3", "COPE_Avoid_4", "COPE_Avoid_5", 
  "COPE_Avoid_6", 
  "CSET_1", "CSET_2", 
  "CSET_3", "CSET_4", "CSET_5", 
  "CSET_6", "CSET_7", "CSET_8", 
  "CSET_9", 
  "date", "instance_id", "key", "last_day",
  "LSEQ_Restlessness", "LSEQ_Wakefulness", 
  "mbl_cod", 
  "MSPSS_SigOth_1", "MSPSS_SigOth_10", "MSPSS_Family_11", 
  "MSPSS_Friends_12", "MSPSS_SigOth_2", "MSPSS_Family_3", 
  "MSPSS_Family_4", "MSPSS_SigOth_5", "MSPSS_Friends_6", 
  "MSPSS_Friends_7", "MSPSS_Family_8", "MSPSS_Friends_9", 
  "PANASSF_Positive_1", "PANASSF_Positive_10", "PANASSF_Negative_11",
  "PANASSF_Positive_12", "PANASSF_Negative_13", "PANASSF_Positive_14",
  "PANASSF_Negative_15", "PANASSF_Positive_16", "PANASSF_Positive_17",
  "PANASSF_Negative_18", "PANASSF_Positive_19", "PANASSF_Negative_2", 
  "PANASSF_Negative_20", "PANASSF_Positive_3", "PANASSF_Negative_4",
  "PANASSF_Positive_5", "PANASSF_Negative_6", "PANASSF_Negative_7",
  "PANASSF_Negative_8", "PANASSF_Positive_9", 
  "PRCS",
  "PROMIS_3A_1", "PROMIS_8A_1",
  "PSQ_Demands_1", "PSQ_NoJoy_2", "PSQ__Tension_3", "PSQ_Worries_4", 
  "PSQ_Worries_5", "PSQ_NoJoy_6", "PSQ_Tension_7", "PSQ_Demands_8", 
  "PTDISF_1", "PTDISF_10", "PTDISF_2", "PTDISF_3", "PTDISF_4", 
  "PTDISF_5", "PTDISF_6", "PTDISF_7", "PTDISF_8", "PTDISF_9",  
  "PTGISF_Life_1", "PTGISF_Relating_10", "PTGISF_Life_2",
  "PTGISF_Possibilities_3", "PTGISF_Spiritual_4", "PTGISF_Relating_5",
  "PTGISF_Possibilities_6", "PTGISF_Strength_7", "PTGISF_Spiritual_8",
  "PTGISF_Strength_9", 
  "REC1", "REC2", 
  "ROE_1", "ROE_2", "ROE_3", "ROE_4", "ROE_5", "ROE_6",
  "rsp_id", "time", "timezone_offset") ->
  colnames(ema_df)

```

Step 4: Create instance means for each scale. Can't use totals because there are different number of items for some subscales am and pm.

LSET and PROMIS are single items, so no averaging is needed.
```{r}

#
# Need to fix COPE...I don't know why the NaN...ah...not asked in the am, so
#  half are missing.
#

ema_df %>%
  mutate(COPE_Approach = rowMeans(across(contains("_Approach_")),
                                  na.rm = TRUE)) %>%
  mutate(COPE_Avoid = rowMeans(across(contains("_Avoid_")),
                               na.rm = TRUE)) %>%
  mutate(PANAS_PA = rowMeans(across(contains("_Positive_")),
                                    na.rm = TRUE)) %>%
  mutate(PANAS_NA = rowMeans(across(contains("_Negative_")),
                             na.rm = TRUE)) %>%
  mutate(CSET = rowMeans(across(contains("CSET")),
                         na.rm = TRUE)) %>%
  mutate(PTDI = rowMeans(across(starts_with("PTDISF_")),
                         na.rm = TRUE)) %>%
  mutate(PTGI_Relate = rowMeans(across(contains("_Relate_")),
                                na.rm = TRUE)) %>%
  mutate(PTGI_Relate = rowMeans(across(contains("_Spiritual_")),
                                na.rm = TRUE)) %>%
  mutate(PTGI_Relate = rowMeans(across(contains("_Possibilities_")),
                                na.rm = TRUE)) %>%
  mutate(PTGI_Life = rowMeans(across(contains("_Life_")),
                              na.rm = TRUE)) %>%
  mutate(PTGI_Strength = rowMeans(across(contains("_Strength_")),
                                  na.rm = TRUE)) %>%
  mutate(PSQ_Demands = rowMeans(across(contains("_Demands_")),
                                na.rm = TRUE)) %>%
  mutate(PSQ_Worries = rowMeans(across(contains("_Worries_")),
                                na.rm = TRUE)) %>%
  mutate(PSQ_Tension = rowMeans(across(contains("_Tension_")),
                                na.rm = TRUE)) %>%
  mutate(PSQ_NoJoy = rowMeans(across(contains("_NoJoy_")),
                              na.rm = TRUE)) %>%
  mutate(ROE = rowMeans(across(starts_with("ROE")),
                        na.rm = TRUE)) %>%
  mutate(MSPSS_SigOth = rowMeans(across(contains("_SigOth_")),
                                 na.rm = TRUE)) %>%
  mutate(MSPSS_Family = rowMeans(across(contains("_Family_")),
                                 na.rm = TRUE)) %>%
  mutate(MSPSS_Friends = rowMeans(across(contains("_Friends_")),
                                  na.rm = TRUE)) ->
  ema_df
```

```{r}
save(ema_df,
     file = here("ema/EMA Data.RData"))
```

## Audio
BTW, the audio files have names something like this:
aud_9891105_1732744605.m4a
The "1732744605" is the instance ID in EMA data. Each can be found in the corresponding mbl_cod folder under the audio folder.

There are 2 formats for the audio data; M4A and 3GG. These appear to be from IOS and Android phones, respectively. Will that matter?

It is impractical to put the audio data into a list; that list would be huge. Hence, all analyses will be done reading in the data using the ID.

We'll ignore the extra (almost empty) folders; if the folder isn't in valid_mobile_codes, then it gets ignored.

For some potential analyses, see: Schultebraucks, K., Yadav, V., Shalev, A. Y., Bonanno, G. A., & Galatzer-Levy, I. R. (2022). Deep learning-based classification of posttraumatic stress disorder and depression following trauma utilizing visual and auditory markers of arousal and mood. Psychological Medicine, 52(5), 957â€“967. https://doi.org/10.1017/S0033291720002718

Chip also indicates that these would be helpful audio analyses: ????

PyPi SpeechRecognition may be useful. However, we may be able to do it in R:

- https://rpubs.com/Ian_M/919060
- https://reintech.io/blog/voice-recognition-with-r-guide-for-developers (especially the seewave package)
- https://reintech.io/blog/speech-recognition-with-r-tutorial
- package:voice
- https://stackoverflow.com/questions/77710695/trying-to-transcribe-audio-files-in-r
- 

First, let's follow this: https://www.bnosac.be/index.php/blog/105-audio-transcription-with-whisper-from-r

```{r bnosac_example}
# devtools::install_github("bnosac/audio.whisper")
# 
# library(audio.whisper)

model <- whisper("tiny")

Sys.time() -> s1

path  <- system.file(package = "audio.whisper", 
                     "samples", 
                     "jfk.wav")
trans <- predict(model, newdata = path, language = "en", n_threads = 2)

Sys.time() -> s2
s2-s1
# Time difference of 0.37 secs

trans

```
That works just fine. Now, start to modify it. Also, note that whisper() can use GPU with a parameter in trans() (NVidia and Metal; the latter is on my MacMini.)

The models are:
tiny, base, small, medium and large-v2. Once built, it isn't a big deal, just disk space.



```{r}
whisper("large-v2") -> model1
```


```{r bnosac_modified}
# devtools::install_github("bnosac/audio.whisper")
# 
# library(audio.whisper)

Sys.time() -> s1

# The model only needs to be loaded once per project; this gets stored
#  in the same folder as this script.
whisper("medium") ->                        # "tiny" v. "medium"????
  model                                     #  "medium" takes a while to load,
                                            #  and to run. 
Sys.time() -> s2

path  <- system.file(package = "audio.whisper", 
                     "samples", 
                     "jfk.wav")

trans <- predict(model,                     # Medium takes 9.74 sec vs tiny 
                 newdata = path,            #  0.37 sec. Much longer. Is it
                 language = "en",           #  worth it?
                 n_threads = 2)
Sys.time() -> s3

s2 - s1
s3 - s2

trans

```
 
```{r audio}
#| echo: FALSE
#| eval: FALSE
#| 
dir(here("audio")) ->
  audio_dir
audio_dir[which(!(dir(here("audio")) %in% keep_codes))] ->
  del_dir
paste0("audio/",
       del_dir) ->
  del_sub_dir

unlink(x = del_sub_dir[1],
       recursive = TRUE)

```


Convert file formats: .3gp and .m4a

```{r audio_convert_tests}
library(av)

av_audio_convert(
  audio = here("audio/52229227/aud_9891105_1744390800.m4a"),
  output = here("test1.wav"))

av_audio_convert(
  audio = here("audio/25890916/aud_9894108_1732590000.3gp"),
  output = here("test2.wav"))

```

These are quite noisy; we probably should filter them before voice-to-text. (Background hiss should be removed.)



## Fitbit Biomarkers



# Joins


# Discards


Now, to merge the EMA data.
```{r}
#| eval: FALSE
# Are the keys unique?

unique(ema_ls[[1]]$key) ->
  keys
for(index in 2:(length(ema_ls))) {
  c(keys, unique(ema_ls[[index]]$key)) ->
    keys
}

length(keys) == length(unique(keys))
# If the preceding is TRUE, then all keys are unique

```

Step 1: Join all the data frames, using a complex key (rsp_id + date + hour)
```{r}
#| eval: FALSE
full_join(ema_ls[[1]],
          ema_ls[[2]],
          by = join_by(key)) ->
  ema_df

# rbind(ema_ls[[12]],
#       ema_ls[[13]]) ->
#   ema_ls[[12]]                              # Same questions for EMA

# 3 -> index
# index + 1 -> index

for(index in 3:13) {
  full_join(ema_df,
            ema_ls[[index]],
            by = join_by(key)) ->
    ema_df
}

ema_df[ , order(names(ema_df))] ->
  ema_df

```

Step 2: Combine items where appropriate. This can be done by rowSums(., na.rm = TRUE)

```{r}
#| eval: FALSE
# There's a better way to do this, I'm sure. However, this is quick and doesn't
#  require much thinking about enquote, assign, etc, so it will save me time.
combine_cols(ema_df, "mbl_cod") -> ema_df
combine_cols(ema_df, "rsp_id") -> ema_df
combine_cols(ema_df, "instance_id") -> ema_df
select_date(ema_df) -> ema_df$date
select_ampm(ema_df) -> ema_df$ampm

# Because the fitbit data is parsed as seconds past midnight, the times
#  here will be seconds past midnight
select_time(ema_df) -> ema_df$time
combine_cols(ema_df, "timezone_offset") -> ema_df

combine_cols(ema_df, "COPE_1") -> ema_df
combine_cols(ema_df, "COPE_2") -> ema_df
combine_cols(ema_df, "COPE_3") -> ema_df
combine_cols(ema_df, "COPE_4") -> ema_df
combine_cols(ema_df, "COPE_5") -> ema_df
combine_cols(ema_df, "COPE_6") -> ema_df

combine_cols(ema_df, "CSET_1") -> ema_df
combine_cols(ema_df, "CSET_2") -> ema_df
combine_cols(ema_df, "CSET_3") -> ema_df
combine_cols(ema_df, "CSET_4") -> ema_df
combine_cols(ema_df, "CSET_5") -> ema_df
combine_cols(ema_df, "CSET_6") -> ema_df
combine_cols(ema_df, "CSET_7") -> ema_df
combine_cols(ema_df, "CSET_8") -> ema_df
combine_cols(ema_df, "CSET_9") -> ema_df

combine_cols(ema_df, "LSEQ_Restlessness") -> ema_df
combine_cols(ema_df, "LSEQ_Wakefulness") -> ema_df

combine_cols(ema_df, "MSPSS_1") -> ema_df
combine_cols(ema_df, "MSPSS_2") -> ema_df
combine_cols(ema_df, "MSPSS_3") -> ema_df
combine_cols(ema_df, "MSPSS_4") -> ema_df
combine_cols(ema_df, "MSPSS_5") -> ema_df
combine_cols(ema_df, "MSPSS_6") -> ema_df
combine_cols(ema_df, "MSPSS_7") -> ema_df
combine_cols(ema_df, "MSPSS_8") -> ema_df
combine_cols(ema_df, "MSPSS_9") -> ema_df
combine_cols(ema_df, "MSPSS_10") -> ema_df
combine_cols(ema_df, "MSPSS_11") -> ema_df
combine_cols(ema_df, "MSPSS_12") -> ema_df

combine_cols(ema_df, "PANASSF_1") -> ema_df
combine_cols(ema_df, "PANASSF_2") -> ema_df
combine_cols(ema_df, "PANASSF_3") -> ema_df
combine_cols(ema_df, "PANASSF_4") -> ema_df
combine_cols(ema_df, "PANASSF_5") -> ema_df
combine_cols(ema_df, "PANASSF_6") -> ema_df
combine_cols(ema_df, "PANASSF_7") -> ema_df
combine_cols(ema_df, "PANASSF_8") -> ema_df
combine_cols(ema_df, "PANASSF_9") -> ema_df
combine_cols(ema_df, "PANASSF_10") -> ema_df
combine_cols(ema_df, "PANASSF_11") -> ema_df
combine_cols(ema_df, "PANASSF_12") -> ema_df
combine_cols(ema_df, "PANASSF_13") -> ema_df
combine_cols(ema_df, "PANASSF_14") -> ema_df
combine_cols(ema_df, "PANASSF_15") -> ema_df
combine_cols(ema_df, "PANASSF_16") -> ema_df
combine_cols(ema_df, "PANASSF_17") -> ema_df
combine_cols(ema_df, "PANASSF_18") -> ema_df
combine_cols(ema_df, "PANASSF_19") -> ema_df
combine_cols(ema_df, "PANASSF_20") -> ema_df

combine_cols(ema_df, "PROMIS_3A_1") -> ema_df
combine_cols(ema_df, "PROMIS_8A_1") -> ema_df

combine_cols(ema_df, "PSQ_1") -> ema_df
combine_cols(ema_df, "PSQ_2") -> ema_df
combine_cols(ema_df, "PSQ_3") -> ema_df
combine_cols(ema_df, "PSQ_4") -> ema_df
combine_cols(ema_df, "PSQ_5") -> ema_df
combine_cols(ema_df, "PSQ_6") -> ema_df
combine_cols(ema_df, "PSQ_7") -> ema_df
combine_cols(ema_df, "PSQ_8") -> ema_df

combine_cols(ema_df, "PTDISF_1") -> ema_df
combine_cols(ema_df, "PTDISF_2") -> ema_df
combine_cols(ema_df, "PTDISF_3") -> ema_df
combine_cols(ema_df, "PTDISF_4") -> ema_df
combine_cols(ema_df, "PTDISF_5") -> ema_df
combine_cols(ema_df, "PTDISF_6") -> ema_df
combine_cols(ema_df, "PTDISF_7") -> ema_df
combine_cols(ema_df, "PTDISF_8") -> ema_df
combine_cols(ema_df, "PTDISF_9") -> ema_df
combine_cols(ema_df, "PTDISF_10") -> ema_df

combine_cols(ema_df, "PTGISF_1") -> ema_df
combine_cols(ema_df, "PTGISF_2") -> ema_df
combine_cols(ema_df, "PTGISF_3") -> ema_df
combine_cols(ema_df, "PTGISF_4") -> ema_df
combine_cols(ema_df, "PTGISF_5") -> ema_df
combine_cols(ema_df, "PTGISF_6") -> ema_df
combine_cols(ema_df, "PTGISF_7") -> ema_df
combine_cols(ema_df, "PTGISF_8") -> ema_df
combine_cols(ema_df, "PTGISF_9") -> ema_df
combine_cols(ema_df, "PTGISF_10") -> ema_df

combine_cols(ema_df, "ROE_1") -> ema_df
combine_cols(ema_df, "ROE_2") -> ema_df
combine_cols(ema_df, "ROE_3") -> ema_df
combine_cols(ema_df, "ROE_4") -> ema_df
combine_cols(ema_df, "ROE_5") -> ema_df
combine_cols(ema_df, "ROE_6") -> ema_df
```

```{r}
#| eval: FALSE
ema_df %>%                                  # Remove the detritus created by
  select(!ends_with("x")) %>%               #  the joins.
  select(!ends_with("y")) ->
  dum1

```

```{r}
#| eval: FALSE

# These are done here to avoid the NA problem in the previous chunk.
combine_rec(ema_df,1) -> ema_df$REC1
combine_rec(ema_df,2) -> ema_df$REC2
combine_prcs(ema_df) -> ema_df$PRCS

ema_df %>%                                  # Remove the detritus created by
  select(!starts_with("PRCS_")) %>%
  select(!starts_with("REC_")) ->
  ema_df

```

```{r more_functions}
#| eval: FALSE
#| # # Setup for testing
# ema_df %>%
#   select(starts_with("COPE_Approach_1")) ->
#   df
# # End testing setup

# combine_cols <- function(df,                # Data frame
#                          item_name) {       # Item Name
# 
#   require(tidyverse)
#   # Note: For some scales, 0 is a legitimate value, while for others it is
#   #  not. Hence, the sort of crazy stuff going on here. This is all to avoid
#   #  the problem where the sum of 6 NA should be NA, not 0.
#   # This probably only works for the data in its current format, because
#   #  there will only be 0 or 1 non-NA values.
#   
#   # The select seems to stop with the first period, so the next is not
#   #  needed.
#   # paste(item_name, ".", sep = "") ->
#   #   item_name
#   
#   df %>%
#     select(starts_with(paste0(item_name,"."))) ->
#     df1
# 
#   NA -> df$x
#   ncol(df1) ->
#     numcol
#   
#   for(rownum in 1:nrow(df)) {
#     if(sum(is.na(df1[rownum,])) != numcol) {
#       sum(df1[rownum,],
#           na.rm = TRUE) ->
#         df$x[rownum]
#     }
#   }  
#   
#   str_split(colnames(df1)[1],                # Rename the x column
#             "[.]")[[1]][1] ->
#     colnames(df)[which(colnames(df) == "x")]
# 
#   return(df)
# }
# 
# # make_key <- function(rsp, 
# #                      posix) {
# #   
# #   vector(mode = "character",
# #          length = length(posix_ls)) ->
# #     key_vec
# #   for(index in 1:length(posix)) {
# #     unlist(str_split(posix, "-| |:")) ->
# #       posix
# # 
# #     paste0(rsp, x[1], x[2], x[3], x[4])
# #   }
# #   
# #   lapply(posix,
# #          function(x) {
# #            paste0(rsp, x[1], x[2], x[3], x[4])
# #          }) ->
# #     key_ls
# #   
# #   
# #   
# #   require(lubridate)
# #   str_replace_all(posix,
# #                   " UTC",
# #                   "") ->
# #     posix
# #   return(
# #     paste0(rsp,
# #            lubridate::year(posix),
# #            lubridate::month(posix),
# #            lubridate::day(posix),
# #            lubridate::hour(posix)))
# # }
# # 
# 
# combine_prcs <- function(df) {
#   require(tidyverse)
#   df %>%
#     select(starts_with("PRCS_")) ->
#     df
#   vector(mode = "character",
#          length = nrow(df)) ->
#     prcs
#   for(index in 1:nrow(df)) {
#     if(sum(is.na(df[index,])) != ncol(df)) {
#       df[index, which(is.na(df[index,]) == FALSE)] ->
#         prcs[index]
#     }
#   }
#   as.numeric(
#     unname(
#       unlist(prcs))) ->
#     prcs
#   return(prcs)
# }
#   
# combine_rec <- function(df,
#                         n) {
#   require(tidyverse)
#   df %>%
#     select(starts_with("REC_")) %>%
#     select(contains(paste0("_",
#                            n,
#                            "_"))) ->
#     df
#   vector(mode = "character",
#          length = nrow(df)) ->
#     rec
#   for(index in 1:nrow(df)) {
#     if(sum(is.na(df[index,])) != ncol(df)) {
#       df[index, which(is.na(df[index,]) == FALSE)] ->
#         rec[index]
#     }
#   }
#   unname(
#     unlist(rec)) ->
#     rec
# 
#   return(rec)
# }
# 


```

